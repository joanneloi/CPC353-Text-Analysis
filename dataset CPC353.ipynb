{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9506bce3-e5f5-41cf-998d-6ddb79ef7d65",
   "metadata": {},
   "source": [
    "1. All text lowercase → ideal for token consistency.\n",
    "2. No URLs, hashtags, markdown, or HTML → avoids token noise.\n",
    "3. No punctuation clutter → helps AntConc tokenize cleanly\n",
    "4. Natural spacing → each line is a full, analyzable sentence/paragraph.\n",
    "5. Accents, emojis, and symbols removed → clean ASCII for corpus tools.\n",
    "6. Joined into plain continuous sentences → perfect for collocation, keyword, and concordance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe09e76-cabe-48e6-9a6c-168e8e8443c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>Regular check-in post, with information about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anyone else just miss physical touch? I crave ...</td>\n",
       "      <td>I haven’t been touched, or even hugged, in so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I’m just so ashamed. Everyone and everything f...</td>\n",
       "      <td>Being Depressed is Embarrassing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I really need a friend. I don't even have a si...</td>\n",
       "      <td>I'm desperate for a friend and to feel loved b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  Welcome to /r/depression's check-in post - a p...   \n",
       "1           1  We understand that most people who reply immed...   \n",
       "2           2  Anyone else just miss physical touch? I crave ...   \n",
       "3           3  I’m just so ashamed. Everyone and everything f...   \n",
       "4           4  I really need a friend. I don't even have a si...   \n",
       "\n",
       "                                               title  target  \n",
       "0  Regular check-in post, with information about ...       1  \n",
       "1  Our most-broken and least-understood rules is ...       1  \n",
       "2  I haven’t been touched, or even hugged, in so ...       1  \n",
       "3                    Being Depressed is Embarrassing       1  \n",
       "4  I'm desperate for a friend and to feel loved b...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"dataset/Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c463a4-d356-4130-a3b6-ec7381c7b780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>Regular check-in post, with information about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anyone else just miss physical touch? I crave ...</td>\n",
       "      <td>I haven’t been touched, or even hugged, in so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m just so ashamed. Everyone and everything f...</td>\n",
       "      <td>Being Depressed is Embarrassing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really need a friend. I don't even have a si...</td>\n",
       "      <td>I'm desperate for a friend and to feel loved b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Welcome to /r/depression's check-in post - a p...   \n",
       "1  We understand that most people who reply immed...   \n",
       "2  Anyone else just miss physical touch? I crave ...   \n",
       "3  I’m just so ashamed. Everyone and everything f...   \n",
       "4  I really need a friend. I don't even have a si...   \n",
       "\n",
       "                                               title  target  \n",
       "0  Regular check-in post, with information about ...       1  \n",
       "1  Our most-broken and least-understood rules is ...       1  \n",
       "2  I haven’t been touched, or even hugged, in so ...       1  \n",
       "3                    Being Depressed is Embarrassing       1  \n",
       "4  I'm desperate for a friend and to feel loved b...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'title', 'target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada58bc7-2195-4983-8b12-1d65e0cb09bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>Regular check-in post, with information about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anyone else just miss physical touch? I crave ...</td>\n",
       "      <td>I haven’t been touched, or even hugged, in so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m just so ashamed. Everyone and everything f...</td>\n",
       "      <td>Being Depressed is Embarrassing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really need a friend. I don't even have a si...</td>\n",
       "      <td>I'm desperate for a friend and to feel loved b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>I’ve (24M) dealt with depression/anxiety for y...</td>\n",
       "      <td>Nobody takes me seriously</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>\"I don't feel very good, it's like I don't be...</td>\n",
       "      <td>selfishness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>I can't sleep most of the nights, meds didn't ...</td>\n",
       "      <td>Is there any way to sleep better?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>Hi, all. I have to give a presentation at work...</td>\n",
       "      <td>Public speaking tips?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>It's not about being scared I didn't lock the ...</td>\n",
       "      <td>I have really bad door anxiety!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5607 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Welcome to /r/depression's check-in post - a p...   \n",
       "1     We understand that most people who reply immed...   \n",
       "2     Anyone else just miss physical touch? I crave ...   \n",
       "3     I’m just so ashamed. Everyone and everything f...   \n",
       "4     I really need a friend. I don't even have a si...   \n",
       "...                                                 ...   \n",
       "5952  I’ve (24M) dealt with depression/anxiety for y...   \n",
       "5953   \"I don't feel very good, it's like I don't be...   \n",
       "5954  I can't sleep most of the nights, meds didn't ...   \n",
       "5955  Hi, all. I have to give a presentation at work...   \n",
       "5956  It's not about being scared I didn't lock the ...   \n",
       "\n",
       "                                                  title  target  \n",
       "0     Regular check-in post, with information about ...       1  \n",
       "1     Our most-broken and least-understood rules is ...       1  \n",
       "2     I haven’t been touched, or even hugged, in so ...       1  \n",
       "3                       Being Depressed is Embarrassing       1  \n",
       "4     I'm desperate for a friend and to feel loved b...       1  \n",
       "...                                                 ...     ...  \n",
       "5952                          Nobody takes me seriously       4  \n",
       "5953                                        selfishness       4  \n",
       "5954                  Is there any way to sleep better?       4  \n",
       "5955                              Public speaking tips?       4  \n",
       "5956                    I have really bad door anxiety!       4  \n",
       "\n",
       "[5607 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['text', 'title', 'target'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3132fc-695a-43c9-8b8d-549877880494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    1202\n",
       "4    1144\n",
       "0    1099\n",
       "2    1085\n",
       "3    1077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46fe863-b5c3-482a-82e7-b19f68ee12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress.csv saved with 1099 rows.\n",
      "Depression.csv saved with 1202 rows.\n",
      "Bipolar_Disorder.csv saved with 1085 rows.\n",
      "Personality_Disorder.csv saved with 1077 rows.\n",
      "Anxiety.csv saved with 1144 rows.\n"
     ]
    }
   ],
   "source": [
    "# Define label mapping\n",
    "label_map = {\n",
    "    0: 'Stress',\n",
    "    1: 'Depression',\n",
    "    2: 'Bipolar_Disorder',\n",
    "    3: 'Personality_Disorder',\n",
    "    4: 'Anxiety'\n",
    "}\n",
    "\n",
    "# Split and save\n",
    "for target, label in label_map.items():\n",
    "    subset = df[df['target'] == target]\n",
    "    subset.to_csv(f\"{label}.csv\", index=False)\n",
    "    print(f\"{label}.csv saved with {len(subset)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3dde69-17ba-4882-9e5c-1b3028f23779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_df = pd.read_csv(\"Stress.csv\")\n",
    "stress_df.head()\n",
    "\n",
    "len(stress_df)  # number of rows in Stress.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac56ac-6f0a-4102-b64c-a6ff78e23fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_df = pd.read_csv(\"datatset/Depression.csv\")\n",
    "\n",
    "depression_df.head()\n",
    "\n",
    "len(depression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07878f0-5aa0-44ff-9c30-a9be614d0f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipolar_disorder_df = pd.read_csv(\"dataset/Bipolar_Disorder.csv\")\n",
    "bipolar_disorder_df.head()\n",
    "\n",
    "len(bipolar_disorder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c038f8e-430f-4d73-a42f-3ab9b952b06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_disorder_df = pd.read_csv(\"dataset/Personality_Disorder.csv\")\n",
    "personality_disorder_df.head()\n",
    "\n",
    "len(personality_disorder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cc18b-9f8a-4080-a997-71f8bde05ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety_df = pd.read_csv(\"dataset/Anxiety.csv\")\n",
    "anxiety_df.head()\n",
    "\n",
    "len(anxiety_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8080438a-c735-47e7-a03c-01936bc58368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c371469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # needed for lemmatization in some setups\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Step 1: Clean text\n",
    "    text = clean_text(text)\n",
    "\n",
    "    # Step 2: Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Step 3: Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Step 4: Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbbff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All resources are available.\n"
     ]
    }
   ],
   "source": [
    "from nltk import data\n",
    "try:\n",
    "    data.find('tokenizers/punkt')\n",
    "    data.find('corpora/stopwords')\n",
    "    data.find('corpora/wordnet')\n",
    "    print(\"All resources are available.\")\n",
    "except LookupError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e6a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All NLTK resources are now installed and ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/joanneloi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, os\n",
    "\n",
    "# Make sure NLTK knows where to look\n",
    "nltk.data.path.append(os.path.expanduser(\"~/nltk_data\"))\n",
    "\n",
    "# Download everything your preprocess_text() needs\n",
    "nltk.download('punkt', download_dir=os.path.expanduser(\"~/nltk_data\"))\n",
    "nltk.download('punkt_tab', download_dir=os.path.expanduser(\"~/nltk_data\"))\n",
    "nltk.download('stopwords', download_dir=os.path.expanduser(\"~/nltk_data\"))\n",
    "nltk.download('wordnet', download_dir=os.path.expanduser(\"~/nltk_data\"))\n",
    "nltk.download('omw-1.4', download_dir=os.path.expanduser(\"~/nltk_data\"))\n",
    "\n",
    "print(\"All NLTK resources are now installed and ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48c122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: Stress.csv\n",
      "Stress_cleaned.csv saved (basic cleaning done).\n",
      "Removed 293 duplicates. 806 entries remain.\n",
      "Stress_cleaned.txt ready for AntConc analysis.\n",
      "\n",
      "Processing dataset: Depression.csv\n",
      "Depression_cleaned.csv saved (basic cleaning done).\n",
      "Removed 228 duplicates. 974 entries remain.\n",
      "Depression_cleaned.txt ready for AntConc analysis.\n",
      "\n",
      "Processing dataset: Bipolar_Disorder.csv\n",
      "Bipolar_Disorder_cleaned.csv saved (basic cleaning done).\n",
      "Removed 276 duplicates. 809 entries remain.\n",
      "Bipolar_Disorder_cleaned.txt ready for AntConc analysis.\n",
      "\n",
      "Processing dataset: Personality_Disorder.csv\n",
      "Personality_Disorder_cleaned.csv saved (basic cleaning done).\n",
      "Removed 185 duplicates. 892 entries remain.\n",
      "Personality_Disorder_cleaned.txt ready for AntConc analysis.\n",
      "\n",
      "Processing dataset: Anxiety.csv\n",
      "Anxiety_cleaned.csv saved (basic cleaning done).\n",
      "Removed 199 duplicates. 945 entries remain.\n",
      "Anxiety_cleaned.txt ready for AntConc analysis.\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "for label in label_map.values():\n",
    "    print(f\"\\nProcessing dataset: {label}.csv\")\n",
    "\n",
    "    df_temp = pd.read_csv(f\"{label}.csv\")\n",
    "\n",
    "    # --- Stage 1: Basic Cleaning ---\n",
    "    df_temp['text'] = df_temp['text'].astype(str).apply(clean_text)\n",
    "    df_temp['title'] = df_temp['title'].astype(str).apply(clean_text)\n",
    "    df_temp.to_csv(f\"{label}_cleaned.csv\", index=False, encoding='utf-8')\n",
    "    print(f\"{label}_cleaned.csv saved (basic cleaning done).\")\n",
    "\n",
    "    # --- Stage 2: Full Preprocessing ---\n",
    "    df_temp['text'] = df_temp['text'].astype(str).apply(lambda x: ' '.join(preprocess_text(x)))\n",
    "    df_temp['title'] = df_temp['title'].astype(str).apply(lambda x: ' '.join(preprocess_text(x)))\n",
    "\n",
    "    # Now both columns are strings again\n",
    "    df_temp['combined'] = df_temp['title'] + \" \" + df_temp['text']\n",
    "\n",
    "    # Normalize, deduplicate, clean\n",
    "    df_temp['combined'] = df_temp['combined'].apply(unidecode)\n",
    "    before = len(df_temp)\n",
    "    df_temp = df_temp.drop_duplicates(subset=['combined'])\n",
    "    after = len(df_temp)\n",
    "    print(f\"Removed {before - after} duplicates. {after} entries remain.\")\n",
    "    df_temp = df_temp[df_temp['combined'].str.strip().str.len() > 3]\n",
    "\n",
    "    # Export for AntConc\n",
    "    df_temp[['combined']].to_csv(f\"{label}_cleaned.txt\", index=False, header=False, encoding='utf-8')\n",
    "    print(f\"{label}_cleaned.txt ready for AntConc analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
